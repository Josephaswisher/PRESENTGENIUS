# Direct AI Provider API Keys (Required - Choose at least one)
VITE_GLM_API_KEY=your_glm_api_key_here  # RECOMMENDED
VITE_DEEPSEEK_API_KEY=sk-your_deepseek_key_here
VITE_MINIMAX_API_KEY=eyJ...your_minimax_key_here
VITE_ANTHROPIC_API_KEY=sk-ant-your_anthropic_key_here  # Claude Sonnet 4.5
VITE_GEMINI_API_KEY=your_gemini_api_key_here  # Gemini 3 Flash
VITE_PERPLEXITY_API_KEY=pplx-your_perplexity_key_here  # For citations & web search

# Alternative Environment Variable Names (for compatibility)
# Uncomment if your deployment platform uses these names:
# GLM_API_KEY=your_glm_api_key_here
# ZAI_API_KEY=your_glm_api_key_here
# DEEPSEEK_API_KEY=sk-your_deepseek_key_here
# minimax_api_key=eyJ...your_minimax_key_here
# ANTHROPIC_API_KEY=sk-ant-your_anthropic_key_here
# GEMINI_API_KEY=your_gemini_api_key_here
# API_KEY=your_gemini_api_key_here  # Google API key alternative

# Supabase (Optional - for cloud storage and sync)
VITE_SUPABASE_URL=your_supabase_project_url
VITE_SUPABASE_ANON_KEY=your_supabase_anon_key

# ============================================================
# SETUP INSTRUCTIONS
# ============================================================
#
# 1. GLM (Zhipu AI - RECOMMENDED - 200K Context)
#    Visit: https://z.ai/console/api-keys
#    Create account and generate API key
#    Copy key to VITE_GLM_API_KEY above
#    Models: glm-4.7, glm-4.6, glm-4.5, glm-4.5-air (200K context)
#    Cost: ~$1-2 input / ~$2-4 output per 1M tokens
#    Why: Latest flagship model (Dec 2025), excellent balance of capability and context
#
# 2. DeepSeek (Most Cost-Effective)
#    Visit: https://platform.deepseek.com/api_keys
#    Create account and generate API key
#    Copy key to VITE_DEEPSEEK_API_KEY above (starts with "sk-")
#    Models: deepseek-chat (64K), deepseek-reasoner (64K)
#    Cost: $0.30 input / $1.20 output per 1M tokens
#
# 3. MiniMax (Large Context Window)
#    Visit: https://platform.minimax.io/user-center/api-key
#    Create account and generate API key
#    Copy key to VITE_MINIMAX_API_KEY above (JWT format, starts with "eyJ")
#    Models: MiniMax-M2.1, MiniMax-M2.1-lightning (200K context)
#    Cost: $0.30 input / $1.20 output per 1M tokens
#
# 4. Claude (Anthropic - Premium - 1M Context)
#    Visit: https://console.anthropic.com/settings/keys
#    Use your Anthropic Max account
#    Generate API key and copy to VITE_ANTHROPIC_API_KEY above (starts with "sk-ant-")
#    Models Available:
#      - claude-sonnet-4-5-20250929 (Recommended): $3 in / $15 out per 1M tokens
#        Extended thinking, streaming, vision, 1M context
#      - claude-opus-4-5-20251101 (Maximum Power): $15 in / $75 out per 1M tokens
#        Supreme reasoning, highest capability, 1M context
#    Features: Streaming responses, vision, extended thinking (1M context window)
#    Why: Choose Sonnet for balanced performance or Opus for maximum reasoning
#
# 5. Gemini 3 (Google AI - 1M Context)
#    Visit: https://aistudio.google.com/app/apikey
#    Create account and generate API key
#    Copy key to VITE_GEMINI_API_KEY above
#    Models Available:
#      - gemini-3-flash-preview (Balanced): $0.50 in / $3.00 out per 1M tokens
#        Fast, 3x faster than 2.5 Pro, near-Pro intelligence
#      - gemini-3-pro-preview (Premium): $2.50 in / $10.00 out per 1M tokens
#        Most advanced reasoning model, superior problem solving
#    Features: Streaming responses, multimodal, thinking level, 1M context
#    Why: Choose Flash for speed or Pro for maximum reasoning capability
#
# 6. Perplexity (Web Search & Citations)
#    Visit: https://www.perplexity.ai/settings/api
#    Create account and generate API key
#    Copy key to VITE_PERPLEXITY_API_KEY above (starts with "pplx-")
#    Models: sonar (128K), sonar-pro (200K)
#    Features: Live web search, automatic citations, medical literature access
#    Use for: Evidence-based content, current guidelines, research citations
#    Cost: $5 input / $5 output per 1M tokens
#
# ENVIRONMENT SETUP:
# 1. Copy this file to .env.local:  cp .env.example .env.local
# 2. Add at least ONE API key to .env.local (GLM recommended)
# 3. Restart development server: npm run dev
# 4. Switch providers in the Chat Assistant panel as needed
#
# RECOMMENDATIONS:
# - GLM (Recommended): Latest flagship model (glm-4.7), optimal balance
# - DeepSeek: Best cost/performance ratio, great for most use cases
# - Claude Sonnet 4.5: Premium model with extended thinking and 1M context
# - Gemini 3 Flash: Near-Pro intelligence at Flash speed with 1M context
# - MiniMax: Alternative large context provider (200K)
# - Perplexity: When you need citations, current medical evidence, or web research
# - You can use multiple providers and switch between them in the UI
#
